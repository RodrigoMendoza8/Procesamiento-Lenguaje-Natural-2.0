{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9ac688fb",
      "metadata": {
        "id": "9ac688fb"
      },
      "source": [
        "# Rodrigo Mendoza Rodriguez SVM Bow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2f6d8d52",
      "metadata": {
        "id": "2f6d8d52"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"author_profiling_pan.zip\", \"r\") as z:\n",
        "    z.extractall(\"carpeta_docs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "75d301ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75d301ab",
        "outputId": "8f0959fc-6bd6-48db-840e-0912c300ae7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "author\n",
            "documents {}\n"
          ]
        }
      ],
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "tree = ET.parse('carpeta_docs/author_profiling_pan/es_test/ff011bde2e7212a3229d462b6809be9b.xml')\n",
        "root = tree.getroot()\n",
        "print(root.tag)\n",
        "for child in root:\n",
        "    print(child.tag, child.attrib)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4b764265",
      "metadata": {
        "id": "4b764265"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "stop_words = set(stopwords.words(\"spanish\"))\n",
        "tokenizer = TweetTokenizer()\n",
        "\n",
        "\n",
        "def limpiar_texto(texto):\n",
        "    texto = BeautifulSoup(texto, \"html.parser\").get_text()\n",
        "    texto = texto.lower()\n",
        "    texto = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", texto)\n",
        "    texto = re.sub(r\"@\\w+\", \"\", texto)\n",
        "    texto = re.sub(r\"#+\", \"\", texto)\n",
        "    tokens = tokenizer.tokenize(texto)\n",
        "    tokens = [tok for tok in tokens if tok not in stop_words]\n",
        "    return \" \".join(tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "03efdbd8",
      "metadata": {
        "id": "03efdbd8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def get_texts_from_folder(path_folder):\n",
        "    tr_txt = []  # aquí van los documentos\n",
        "    tr_y = []    # aquí van las etiquetas\n",
        "\n",
        "    for file in os.listdir(path_folder):\n",
        "        if file.endswith(\".xml\"):\n",
        "            tree = ET.parse(os.path.join(path_folder, file))\n",
        "            root = tree.getroot()\n",
        "            docs = []\n",
        "            for doc in root.iter(\"document\"):\n",
        "                texto_limpio = limpiar_texto(doc.text)\n",
        "                if texto_limpio:  #\n",
        "                    docs.append(texto_limpio)\n",
        "            if docs:\n",
        "                tr_txt.append(\" \".join(docs))\n",
        "\n",
        "    truth_file = os.path.join(path_folder, \"truth.txt\")\n",
        "    if os.path.exists(truth_file):\n",
        "        file_to_label = {}\n",
        "        with open(truth_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split(\":::\")\n",
        "                if len(parts) >= 3:\n",
        "                    file_to_label[parts[0]] = parts[2]\n",
        "\n",
        "        for file in os.listdir(path_folder):\n",
        "            if file.endswith(\".xml\"):\n",
        "                file_id = file.split('.')[0]\n",
        "                if file_id in file_to_label:\n",
        "                    tr_y.append(file_to_label[file_id])\n",
        "\n",
        "    return tr_txt, tr_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4fe124d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fe124d4",
        "outputId": "50854b45-c417-4a7d-e769-bc82cf7aa02c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Personal Computer\\AppData\\Local\\Temp\\ipykernel_22532\\2710110333.py:11: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  texto = BeautifulSoup(texto, \"html.parser\").get_text()\n",
            "C:\\Users\\Personal Computer\\AppData\\Local\\Temp\\ipykernel_22532\\2710110333.py:11: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  texto = BeautifulSoup(texto, \"html.parser\").get_text()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Textos train: 4200, Etiquetas train: 4200\n",
            "Textos test: 2800, Etiquetas test: 2800\n"
          ]
        }
      ],
      "source": [
        "path_test = 'carpeta_docs/author_profiling_pan/es_test/'\n",
        "path_train = 'carpeta_docs/author_profiling_pan/es_train/'\n",
        "tr_txt_train, tr_y_train = get_texts_from_folder(path_train)\n",
        "tr_txt_test, tr_y_test = get_texts_from_folder(path_test)\n",
        "\n",
        "print(f\"Textos train: {len(tr_txt_train)}, Etiquetas train: {len(tr_y_train)}\")\n",
        "print(f\"Textos test: {len(tr_txt_test)}, Etiquetas test: {len(tr_y_test)}\")\n",
        "\n",
        "all_countries = sorted(list(set(tr_y_train + tr_y_test)))\n",
        "paises_numericas = {pais: idx for idx, pais in enumerate(all_countries)}\n",
        "\n",
        "y_train = [paises_numericas[pais] for pais in tr_y_train]\n",
        "y_test = [paises_numericas[pais] for pais in tr_y_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d6bb4cab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6bb4cab",
        "outputId": "bfb46e3e-47b3-4ba7-ace1-b130ed41e4da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4200"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tr_txt_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a29115cf",
      "metadata": {
        "id": "a29115cf"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "\n",
        "corpus_de_palabras = []\n",
        "for doc in tr_txt_train:\n",
        "    if doc and isinstance(doc, str):\n",
        "        corpus_de_palabras += tokenizer.tokenize(doc)\n",
        "\n",
        "fdist = nltk.FreqDist(corpus_de_palabras)\n",
        "V = [word for word, _ in fdist.most_common(10000)]\n",
        "dict_indices = {word: i for i, word in enumerate(V)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "50270c95",
      "metadata": {
        "id": "50270c95"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def built_bow_tr_binario(tr_txt, vocabulario, dict_indices):\n",
        "    bow = np.zeros((len(tr_txt), len(vocabulario)), dtype=np.int8)\n",
        "    for cont_doc, tr in enumerate(tr_txt):\n",
        "        if not tr or not isinstance(tr, str):\n",
        "            continue\n",
        "        tokens = tokenizer.tokenize(tr.lower())\n",
        "        for word in tokens:\n",
        "            if word in dict_indices:\n",
        "                bow[cont_doc, dict_indices[word]] = 1\n",
        "    return bow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d069ee66",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d069ee66",
        "outputId": "1df153aa-ba0c-4381-9d76-177f5366bd17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 0, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 1, 1, 1],\n",
              "       ...,\n",
              "       [1, 0, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 0, ..., 0, 0, 0]], dtype=int8)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bow_tr = built_bow_tr_binario(tr_txt_train, V, dict_indices)\n",
        "bow_tr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "1860e8ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1860e8ab",
        "outputId": "9a3d0e6f-a563-48e9-fddf-ef653b9e0ce6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4200, 10000)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bow_tr.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1236befc",
      "metadata": {
        "id": "1236befc"
      },
      "source": [
        "# Ejercicio 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4ab53b77",
      "metadata": {
        "id": "4ab53b77"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm, metrics\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_recall_fscore_support, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "50983460",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50983460",
        "outputId": "37c44894-c4e9-46a3-c3f0-3852f05e8011"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[116   0   1   0   1   1   1]\n",
            " [  1 117   2   0   0   0   0]\n",
            " [  0   1 112   2   3   0   2]\n",
            " [  0   1   3 112   1   1   2]\n",
            " [  1   0   2   3 111   2   1]\n",
            " [  0   0   0   0   1 115   4]\n",
            " [  0   0   3   2   1   1 113]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.97       120\n",
            "           1       0.98      0.97      0.98       120\n",
            "           2       0.91      0.93      0.92       120\n",
            "           3       0.94      0.93      0.94       120\n",
            "           4       0.94      0.93      0.93       120\n",
            "           5       0.96      0.96      0.96       120\n",
            "           6       0.92      0.94      0.93       120\n",
            "\n",
            "    accuracy                           0.95       840\n",
            "   macro avg       0.95      0.95      0.95       840\n",
            "weighted avg       0.95      0.95      0.95       840\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X_train80, X_val20, y_train80, y_val20 = train_test_split(\n",
        "    bow_tr, y_train, test_size=0.2, stratify=y_train, random_state=42\n",
        ")\n",
        "parameters = {'C': [0.01, 0.05, 0.1, 0.5, 1, 2, 5, 10]}\n",
        "svr = svm.LinearSVC(class_weight='balanced', max_iter=10000)\n",
        "\n",
        "grid = GridSearchCV(estimator=svr, param_grid=parameters, n_jobs=4, scoring='f1_macro', cv=5)\n",
        "grid.fit(X_train80, y_train80)\n",
        "y_pred = grid.predict(X_val20)\n",
        "\n",
        "p, r, f, _ = precision_recall_fscore_support(y_val20, y_pred, average='weighted')\n",
        "\n",
        "print(confusion_matrix(y_val20, y_pred))\n",
        "print(metrics.classification_report(y_val20, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f11f123c",
      "metadata": {
        "id": "f11f123c"
      },
      "source": [
        "# Ejercicio 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "95bb76e5",
      "metadata": {
        "id": "95bb76e5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def built_bow_tr_frecuencia(tr_txt, vocabulario, dict_indices):\n",
        "    bow = np.zeros((len(tr_txt), len(vocabulario)), dtype=int)\n",
        "    for cont_doc, tr in enumerate(tr_txt):\n",
        "        if not tr or not isinstance(tr, str):\n",
        "            continue\n",
        "        tokens = tokenizer.tokenize(tr.lower())\n",
        "        fdist_doc = nltk.FreqDist(tokens)\n",
        "        for word in fdist_doc:\n",
        "            if word in dict_indices:\n",
        "                bow[cont_doc, dict_indices[word]] = fdist_doc[word]\n",
        "    return bow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "838393d6",
      "metadata": {
        "id": "838393d6"
      },
      "outputs": [],
      "source": [
        "tokenizer = TweetTokenizer()\n",
        "corpus_de_palabras_f = []\n",
        "for doc in tr_txt_train:\n",
        "    if isinstance(doc, str):\n",
        "        corpus_de_palabras_f += tokenizer.tokenize(doc)\n",
        "\n",
        "fdist = nltk.FreqDist(corpus_de_palabras_f)\n",
        "\n",
        "V_f = [word for word, _ in fdist.most_common(10000)]\n",
        "dict_indices_f = {word: i for i, word in enumerate(V_f)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "cc1bf6c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc1bf6c0",
        "outputId": "0dd5e7f6-444f-4cdc-c09f-4a853ba25c65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 34  14  73 ...   0   0   0]\n",
            " [ 21   3   0 ...   0   0   0]\n",
            " [ 48  73  11 ...   3   1   2]\n",
            " ...\n",
            " [ 11   0  22 ...   0   0   0]\n",
            " [ 67  24   4 ...   0   0   0]\n",
            " [ 52 107   0 ...   0   0   0]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(4200, 10000)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bow_train_frecuencia = built_bow_tr_frecuencia(tr_txt_train,V_f,dict_indices_f)\n",
        "print(bow_train_frecuencia)\n",
        "bow_train_frecuencia.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "3b2ed50f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b2ed50f",
        "outputId": "23ac5ffd-94ea-4616-9d5c-c31868116a72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[110   0   2   0   5   1   2]\n",
            " [  1 115   1   0   2   0   1]\n",
            " [  0   1 108   1   8   0   2]\n",
            " [  0   2   5 101   5   3   4]\n",
            " [  3   0   2   4 108   2   1]\n",
            " [  2   0   1   3   1 112   1]\n",
            " [  1   2   4   4   3   2 104]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.92      0.93       120\n",
            "           1       0.96      0.96      0.96       120\n",
            "           2       0.88      0.90      0.89       120\n",
            "           3       0.89      0.84      0.87       120\n",
            "           4       0.82      0.90      0.86       120\n",
            "           5       0.93      0.93      0.93       120\n",
            "           6       0.90      0.87      0.89       120\n",
            "\n",
            "    accuracy                           0.90       840\n",
            "   macro avg       0.90      0.90      0.90       840\n",
            "weighted avg       0.90      0.90      0.90       840\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X_train80, X_val20, y_train80, y_val20 = train_test_split(\n",
        "    bow_train_frecuencia, y_train, test_size=0.2, stratify=y_train, random_state=42\n",
        ")\n",
        "parameters = {'C': [0.01, 0.05, 0.1, 0.5, 1, 2, 5, 10]}\n",
        "svr = svm.LinearSVC(class_weight='balanced', max_iter=10000)\n",
        "grid = GridSearchCV(estimator=svr, param_grid=parameters, n_jobs=4, scoring='f1_macro', cv=5)\n",
        "grid.fit(X_train80, y_train80)\n",
        "y_pred = grid.predict(X_val20)\n",
        "\n",
        "p, r, f, _ = precision_recall_fscore_support(y_val20, y_pred, average='macro')\n",
        "\n",
        "print(confusion_matrix(y_val20, y_pred))\n",
        "print(metrics.classification_report(y_val20, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97937ecc",
      "metadata": {
        "id": "97937ecc"
      },
      "source": [
        "# Ejercicio 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "e46cdf00",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e46cdf00",
        "outputId": "fa09d669-f327-432e-aef2-fbbd644e1f5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[115   1   0   2   0   1   1]\n",
            " [  0 111   3   2   2   1   1]\n",
            " [  0   1 112   2   2   1   2]\n",
            " [  1   0   3 109   3   2   2]\n",
            " [  2   0   0   1 111   4   2]\n",
            " [  0   0   0   1   0 118   1]\n",
            " [  0   0   4   3   2   2 109]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.96      0.97       120\n",
            "           1       0.98      0.93      0.95       120\n",
            "           2       0.92      0.93      0.93       120\n",
            "           3       0.91      0.91      0.91       120\n",
            "           4       0.93      0.93      0.93       120\n",
            "           5       0.91      0.98      0.95       120\n",
            "           6       0.92      0.91      0.92       120\n",
            "\n",
            "    accuracy                           0.93       840\n",
            "   macro avg       0.94      0.93      0.93       840\n",
            "weighted avg       0.94      0.93      0.93       840\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "bow_tr = bow_tr.astype(np.float32)\n",
        "bow_train_L2 = normalize(bow_tr, norm='l2')\n",
        "X_train80, X_val20, y_train80, y_val20 = train_test_split(\n",
        "    bow_train_L2, y_train, test_size=0.2, stratify=y_train\n",
        ")\n",
        "parameters = {'C': [0.01, 0.05, 0.1, 0.5, 1, 2, 5, 10]}\n",
        "svr = svm.LinearSVC(class_weight='balanced', max_iter=10000)\n",
        "\n",
        "grid = GridSearchCV(estimator=svr, param_grid=parameters, n_jobs=4, scoring='f1_macro', cv=5)\n",
        "grid.fit(X_train80, y_train80)\n",
        "y_pred = grid.predict(X_val20)\n",
        "\n",
        "p, r, f, _ = precision_recall_fscore_support(y_val20, y_pred, average='macro')\n",
        "\n",
        "print(confusion_matrix(y_val20, y_pred))\n",
        "print(metrics.classification_report(y_val20, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce8877ef",
      "metadata": {
        "id": "ce8877ef"
      },
      "source": [
        "# Ejercicio 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "d11d050b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d11d050b",
        "outputId": "2bc79cda-e963-49c7-c51d-31ac05882d31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[111   0   2   1   3   1   2]\n",
            " [  0 115   1   0   2   1   1]\n",
            " [  0   1 112   1   5   0   1]\n",
            " [  0   2   6 100   4   3   5]\n",
            " [  0   2   3   4 107   2   2]\n",
            " [  3   0   0   1   1 110   5]\n",
            " [  1   1   7   2   3   3 103]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.93      0.94       120\n",
            "           1       0.95      0.96      0.95       120\n",
            "           2       0.85      0.93      0.89       120\n",
            "           3       0.92      0.83      0.87       120\n",
            "           4       0.86      0.89      0.87       120\n",
            "           5       0.92      0.92      0.92       120\n",
            "           6       0.87      0.86      0.86       120\n",
            "\n",
            "    accuracy                           0.90       840\n",
            "   macro avg       0.90      0.90      0.90       840\n",
            "weighted avg       0.90      0.90      0.90       840\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "bow_train_frecuencia = bow_train_frecuencia.astype(np.float32)\n",
        "bow_train_frecuencia_L2 = normalize(bow_train_frecuencia, norm='l2')\n",
        "\n",
        "X_train80, X_val20, y_train80, y_val20 = train_test_split(\n",
        "    bow_train_frecuencia_L2, y_train, test_size=0.2, stratify=y_train, random_state=42\n",
        ")\n",
        "parameters = {'C': [0.01, 0.05, 0.1, 0.5, 1, 2, 5, 10]}\n",
        "svr = svm.LinearSVC(class_weight='balanced', max_iter=10000)\n",
        "grid = GridSearchCV(estimator=svr, param_grid=parameters, n_jobs=4, scoring='f1_macro', cv=5)\n",
        "grid.fit(X_train80, y_train80)\n",
        "y_pred = grid.predict(X_val20)\n",
        "\n",
        "p, r, f, _ = precision_recall_fscore_support(y_val20, y_pred, average='macro')\n",
        "\n",
        "print(confusion_matrix(y_val20, y_pred))\n",
        "print(metrics.classification_report(y_val20, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "5G0T6gxcYtjP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G0T6gxcYtjP",
        "outputId": "c8b1e073-2070-4303-c62f-b868412a423b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TABLA COMPARATIVA DE LOS 4 EJERCICIOS\n",
            "==================================================\n",
            "                        Accuracy  F1-Score (Macro)  F1-Score (Weighted)  \\\n",
            "Experimento                                                               \n",
            "1. BOW Binario              0.94              0.94                 0.94   \n",
            "2. BOW Frecuencia           0.91              0.91                 0.91   \n",
            "3. BOW Binario + L2         0.95              0.95                 0.95   \n",
            "4. BOW Frecuencia + L2      0.92              0.92                 0.92   \n",
            "\n",
            "                        Precisión (Macro)  \n",
            "Experimento                                \n",
            "1. BOW Binario                       0.95  \n",
            "2. BOW Frecuencia                    0.91  \n",
            "3. BOW Binario + L2                  0.95  \n",
            "4. BOW Frecuencia + L2               0.92  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Tabla comparativa con los resultados de tus 4 ejercicios\n",
        "tabla_comparativa = {\n",
        "    'Experimento': ['1. BOW Binario', '2. BOW Frecuencia', '3. BOW Binario + L2', '4. BOW Frecuencia + L2'],\n",
        "    'Accuracy': [0.94, 0.91, 0.95, 0.92],  # Reemplaza 0.XX con tus valores\n",
        "    'F1-Score (Macro)': [0.94, 0.91, 0.95, 0.92],  # Reemplaza 0.XX con tus valores\n",
        "    'F1-Score (Weighted)': [0.94, 0.91, 0.95, 0.92],  # Reemplaza 0.XX con tus valores\n",
        "    'Precisión (Macro)': [0.95, 0.91, 0.95, 0.92]  # Reemplaza 0.XX con tus valores\n",
        "}\n",
        "\n",
        "df_comparativo = pd.DataFrame(tabla_comparativa)\n",
        "df_comparativo = df_comparativo.set_index('Experimento')\n",
        "\n",
        "print(\"TABLA COMPARATIVA DE LOS 4 EJERCICIOS\")\n",
        "print(\"=\" * 50)\n",
        "print(df_comparativo.round(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ywTirSTDJvYr",
      "metadata": {
        "id": "ywTirSTDJvYr"
      },
      "source": [
        "# Comentario personal\n",
        "Considero que el experimento 3 de Binario con normalizacion de L2 fue el que mejores resultados lanzo, tardo mucho menos en comparacion de los otros y consiguio una mejor puntuacion en las metricas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c82f678c",
      "metadata": {
        "id": "c82f678c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
